{
  "posts": [
    {
      "id": "llm-structured-output-tool-calling",
      "title": "LLM Structured Output: Just Tool Calling in Disguise",
      "slug": "llm-structured-output-tool-calling",
      "category": "research",
      "categoryLabel": "Research",
      "date": "2025-11-13",
      "readTime": "7 min read",
      "author": {
        "name": "Duc Le",
        "avatar": "data/images/image_avatar.jpg",
        "title": "AI Engineer & Researcher"
      },
      "excerpt": "A deep dive into how structured output in modern LLMs is actually implemented through tool calling mechanisms, not as a separate capability. Understanding this reveals important insights about LLM architecture and constraints.",
      "image": "https://via.placeholder.com/1200x600",
      "tags": ["LLM", "AI", "Structured Output", "Tool Calling", "JSON", "OpenAI", "Anthropic"],
      "featured": true,
      "sections": [
        {
          "id": "introduction",
          "title": "1. Introduction",
          "content": "Many developers believe that LLMs have a special \"structured output\" mode that generates perfectly formatted JSON or XML. In reality, most modern LLM APIs implement structured output through their existing tool calling infrastructureâ€”it's essentially a clever wrapper around function calling."
        },
        {
          "id": "what-is-structured-output",
          "title": "2. What is Structured Output?",
          "content": "Structured output refers to the ability of an LLM to generate responses that conform to a specific schema or format, typically JSON. This is useful for:\n\nâ€¢ Extracting structured data from unstructured text\nâ€¢ Generating API-ready responses\nâ€¢ Ensuring type safety in downstream applications\nâ€¢ Building reliable AI pipelines\n\nExample:\n```json\n{\n  \"name\": \"John Doe\",\n  \"age\": 30,\n  \"email\": \"john@example.com\"\n}\n```"
        },
        {
          "id": "tool-calling-mechanism",
          "title": "3. The Tool Calling Mechanism",
          "content": "Tool calling (also known as function calling) is a feature where LLMs can decide to invoke external functions with specific parameters. The process works like this:\n\n1. You provide the LLM with function definitions (schemas)\n2. The LLM analyzes the user's request\n3. If appropriate, it generates a function call with properly formatted arguments\n4. Your application executes the function and returns results\n5. The LLM incorporates the results into its response"
        },
        {
          "id": "structured-output-implementation",
          "title": "4. How Structured Output Uses Tool Calling",
          "content": "When you request structured output, here's what actually happens behind the scenes:",
          "nestedList": [
            {
              "text": "Schema Definition",
              "children": [
                "You provide a JSON schema defining your desired output structure",
                "The API converts this schema into a \"virtual tool\" or function definition",
                "This tool has a name like 'generate_structured_output' or similar"
              ]
            },
            {
              "text": "Forced Tool Call",
              "children": [
                "The API instructs the LLM to always call this virtual tool",
                "The LLM treats your schema as function parameters",
                "It generates the structured data as tool arguments"
              ]
            },
            {
              "text": "Response Formatting",
              "children": [
                "The API intercepts the tool call response",
                "It extracts the structured arguments",
                "Returns them directly to you as 'structured output'"
              ]
            }
          ]
        },
        {
          "id": "evidence",
          "title": "5. Evidence from API Providers",
          "content": "Several pieces of evidence support this implementation approach:",
          "table": {
            "headers": ["Provider", "Evidence", "Details"],
            "rows": [
              ["OpenAI", "API Parameter Names", "The 'response_format' parameter and 'tools' parameter share similar schema definitions. Structured output uses 'json_schema' type which mirrors tool definitions."],
              ["Anthropic Claude", "Tool Use Architecture", "Claude's structured output is explicitly implemented through their tool use system. You can see this in their API documentation."],
              ["Constraint Behavior", "Error Patterns", "Structured output fails in the same ways as tool calling: schema violations, missing required fields, type mismatches."],
              ["Token Limits", "Shared Constraints", "Both structured output and tool calling share the same token limitations for schemas and responses."]
            ]
          }
        },
        {
          "id": "why-this-matters",
          "title": "6. Why This Implementation Matters",
          "content": "Understanding that structured output is tool calling has practical implications:",
          "nestedList": [
            {
              "text": "Performance Characteristics",
              "children": [
                "Structured output has the same latency as tool calling",
                "Token usage follows tool calling patterns",
                "Complexity limits are inherited from tool definitions"
              ]
            },
            {
              "text": "Reliability Considerations",
              "children": [
                "Schema validation happens at the tool level",
                "Complex nested structures may fail like complex tool schemas",
                "Retry logic should mirror tool calling strategies"
              ]
            },
            {
              "text": "Feature Limitations",
              "children": [
                "Can't use structured output AND custom tools simultaneously in some APIs",
                "Schema complexity is bounded by tool definition limits",
                "Some models support tools but not 'structured output' (they're the same!)"
              ]
            }
          ]
        },
        {
          "id": "code-example",
          "title": "7. Practical Example",
          "content": "Here's how you might implement structured output manually using tool calling:\n\n```python\n# Instead of using 'structured output' API\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"extract_user_info\",\n            \"description\": \"Extract user information\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"name\": {\"type\": \"string\"},\n                    \"age\": {\"type\": \"integer\"},\n                    \"email\": {\"type\": \"string\"}\n                },\n                \"required\": [\"name\", \"age\", \"email\"]\n            }\n        }\n    }\n]\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[{\"role\": \"user\", \"content\": \"John is 30 and his email is john@example.com\"}],\n    tools=tools,\n    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"extract_user_info\"}}\n)\n\n# Extract the structured data from tool call\nstructured_data = response.choices[0].message.tool_calls[0].function.arguments\n```\n\nThis is essentially what the structured output API does internally!"
        },
        {
          "id": "best-practices",
          "title": "8. Best Practices",
          "content": "Keep schemas simple and flat when possible\n\nTest with tool calling first to understand failure modes\n\nImplement the same error handling as you would for tools\n\nConsider token costsâ€”complex schemas increase prompt tokens\n\nUse validation libraries to verify output even with structured mode\n\nBe aware that not all models support the same schema complexity"
        },
        {
          "id": "conclusion",
          "title": "9. Conclusion",
          "content": "Structured output in LLMs isn't a magical new capabilityâ€”it's a well-designed abstraction over tool calling. By understanding this implementation detail, you can:\n\nâ€¢ Better debug issues with structured output\nâ€¢ Optimize your schemas for better performance\nâ€¢ Make informed decisions about when to use structured output vs. manual parsing\nâ€¢ Understand the limitations and constraints you'll face\n\nThe next time an API provider announces 'improved structured output,' check if they're really just improving their tool calling infrastructure. Chances are, they are!"
        }
      ]
    },
    {
      "id": "api-request-data-transmission",
      "title": "API Request Data Transmission Guide",
      "slug": "api-request-data-transmission",
      "category": "tutorial",
      "categoryLabel": "Tutorial",
      "date": "2025-11-10",
      "readTime": "6 min read",
      "author": {
        "name": "Duc Le",
        "avatar": "data/images/image_avatar.jpg",
        "title": "Software Engineer & Researcher"
      },
      "excerpt": "A comprehensive guide to understanding parameters in GET requests and body payloads in POST requests, with practical examples and best practices for API development.",
      "image": "https://via.placeholder.com/1200x600",
      "tags": ["API", "HTTP", "REST", "GET", "POST", "Web Development"],
      "featured": true,
      "sections": [
        {
          "id": "parameters-get",
          "title": "1. Parameters for GET Requests",
          "content": "Parameters are pieces of information sent along with the URL to filter, sort, paginate, or identify resources in a GET request. They do not modify server data."
        },
        {
          "id": "parameter-types",
          "title": "Types of Parameters",
          "content": "There are three main types of parameters used in GET requests."
        },
        {
          "id": "path-parameters",
          "title": "Path Parameters",
          "content": "Appear in the URL path.\n\nUsed to identify specific resources.\n\nExample:\n```\nGET /users/123\n```\n\nHere `123` identifies a specific user."
        },
        {
          "id": "query-parameters",
          "title": "Query Parameters",
          "content": "Appear after `?` in the URL.\n\nUsed for filtering, sorting, and pagination.\n\nExample:\n```\nGET /users?role=admin&page=2&limit=10\n```"
        },
        {
          "id": "header-parameters",
          "title": "Header Parameters (Optional)",
          "content": "Sent in the HTTP headers.\n\nOften used for authentication or specifying response format.\n\nExample:\n```\nAuthorization: Bearer <token>\nAccept-Language: en-US\n```"
        },
        {
          "id": "get-guidelines",
          "title": "Guidelines for GET Parameters",
          "content": "Use parameters for retrieving or filtering data only.\n\nKeep query parameters short; avoid sending sensitive information.\n\nDo not include large payloads in GET requests; use POST instead."
        },
        {
          "id": "body-post",
          "title": "2. Body for POST Requests",
          "content": "The body of a POST request contains the main data payload sent to the server, often used to create new resources. It may include structured data such as JSON, XML, or form data."
        },
        {
          "id": "body-formats",
          "title": "Body Formats",
          "content": "**application/json** - JSON object\nExample: `{ \"name\": \"John\", \"email\": \"john@example.com\" }`\n\n**application/x-www-form-urlencoded** - Key-value pairs\nExample: `name=John&email=john@example.com`\n\n**multipart/form-data** - Mixed data, often including files\nExample: Form submission with file upload"
        },
        {
          "id": "post-example",
          "title": "POST Request Example",
          "content": "```\nPOST /users\nHost: example.com\nContent-Type: application/json\n\n{\n  \"name\": \"Le Ngoc Duc\",\n  \"email\": \"duc@example.com\",\n  \"password\": \"secure123\"\n}\n```"
        },
        {
          "id": "post-guidelines",
          "title": "Guidelines for POST Body",
          "content": "Use POST body for creating resources or submitting forms.\n\nInclude complex or sensitive data in the body, not in query parameters.\n\nAlways set the appropriate Content-Type header.\n\nKeep the payload structured and validate it server-side."
        },
        {
          "id": "summary",
          "title": "3. Summary",
          "content": "**GET Request** - Data Location: Parameters (Path / Query / Header) - Purpose: Retrieve or filter resources\n\n**POST Request** - Data Location: Body / Payload - Purpose: Create new resources or submit data\n\nðŸ’¡ Note: In API terminology, payload usually refers to the data inside the body â€” the actual content sent to the server."
        }
      ]
    },
    {
      "id": "normal-distribution-ai",
      "title": "Use of Normal Distribution in AI: Causes and Effects",
      "slug": "normal-distribution-ai",
      "category": "research",
      "categoryLabel": "Research",
      "date": "2025-11-10",
      "readTime": "10 min read",
      "author": {
        "name": "Duc Le",
        "avatar": "data/images/image_avatar.jpg",
        "title": "Software Engineer & Researcher"
      },
      "excerpt": "A comprehensive technical analysis of why normal distribution is used in AI systems, distinguishing between mathematical causes and practical benefits in modeling, optimization, and generative processes.",
      "image": "https://via.placeholder.com/1200x600",
      "tags": ["AI", "Machine Learning", "Statistics", "Probability", "Deep Learning", "Research"],
      "featured": true,
      "sections": [
        {
          "id": "introduction",
          "title": "1. Introduction",
          "content": "The normal distribution, also known as Gaussian distribution, is one of the most widely used probability distributions in AI. Its prevalence is due to both mathematical properties and practical benefits in modeling, optimization, and generative processes.\n\nThis document explicitly separates causes (why we assume/use normal distribution) from effects (what advantages or outcomes result from this assumption)."
        },
        {
          "id": "causes",
          "title": "2. Causes (Why Normal Distribution is Used)",
          "content": "Understanding why normal distribution is fundamental to AI requires examining several mathematical and practical foundations.",
          "table": {
            "headers": ["Cause", "Explanation"],
            "rows": [
              ["Central Limit Theorem (CLT)", "When many independent random variables are summed, their normalized sum tends toward a Gaussian distribution. Many features, errors, or aggregated signals in AI naturally approximate this."],
              ["Natural Occurrence in Data", "Real-world phenomena, measurement noise, and environmental variations often follow Gaussian-like patterns."],
              ["Mathematical Convenience", "Gaussian distributions have closed-form expressions for probability density, conditional probability, and convolution, which simplifies probabilistic modeling and derivation."],
              ["Smoothness of the Distribution", "Normal distribution is continuous, differentiable, and fully characterized by mean and variance, which facilitates optimization and learning in neural networks."],
              ["Prior Knowledge in Probabilistic Models", "In Bayesian models, assuming Gaussian priors or likelihoods simplifies posterior computation (e.g., conjugate priors)."],
              ["Generative Process Assumptions", "In models like diffusion models or VAEs, Gaussian noise is assumed in the latent or input space to enable sampling and reconstruction."],
              ["Weight Initialization in Neural Networks", "Randomly initializing weights with Gaussian distributions stabilizes forward activations and backward gradients."]
            ]
          }
        },
        {
          "id": "effects",
          "title": "3. Effects / Benefits (What Using Normal Distribution Gives)",
          "content": "The use of normal distribution in AI systems produces several concrete benefits and practical advantages.",
          "table": {
            "headers": ["Effect", "Linked Cause", "Explanation"],
            "rows": [
              ["Efficient Probabilistic Computation", "Mathematical convenience", "Allows closed-form calculations for marginal and conditional probabilities. Useful in Gaussian Naive Bayes, Kalman filters, and Gaussian Processes."],
              ["Stable Training of Neural Networks", "Weight initialization & smoothness", "Gaussian initialization prevents gradient vanishing/explosion, enabling better convergence."],
              ["Controlled Noise Injection", "Generative process assumptions", "Adding Gaussian noise during training or diffusion improves robustness and sample diversity."],
              ["Latent Variable Modeling", "Prior knowledge in probabilistic models", "Enables efficient sampling, reparameterization trick, and approximate inference in VAEs."],
              ["Better Approximation of Aggregate Effects", "CLT", "Justifies modeling errors or combined feature effects as Gaussian, which simplifies model assumptions and optimization."],
              ["Predictable Statistical Properties", "Mathematical convenience", "Mean, variance, and higher moments are well-defined and interpretable, aiding analysis and debugging."]
            ]
          }
        },
        {
          "id": "examples",
          "title": "4. Examples in AI Models",
          "content": "Let's examine how normal distribution is used in specific AI models and techniques.",
          "nestedList": [
            {
              "text": "Kalman Filter",
              "children": [
                "Use: Process and measurement noise assumed Gaussian",
                "Cause: CLT, measurement errors",
                "Effect: Closed-form recursive estimation"
              ]
            },
            {
              "text": "Variational Autoencoder (VAE)",
              "children": [
                "Use: Latent variables follow Gaussian prior",
                "Cause: Probabilistic prior assumption",
                "Effect: Easy sampling and backpropagation via reparameterization trick"
              ]
            },
            {
              "text": "Diffusion Models",
              "children": [
                "Use: Gaussian noise added in forward process",
                "Cause: Generative process assumption",
                "Effect: Enables controlled denoising and reconstruction"
              ]
            },
            {
              "text": "Neural Network Weight Initialization",
              "children": [
                "Use: Random Gaussian initialization",
                "Cause: Smooth, differentiable distribution",
                "Effect: Stable training and faster convergence"
              ]
            },
            {
              "text": "Gaussian Naive Bayes",
              "children": [
                "Use: Features modeled with Gaussian likelihood",
                "Cause: Data approximation",
                "Effect: Tractable classification probabilities"
              ]
            }
          ]
        },
        {
          "id": "summary",
          "title": "5. Summary",
          "content": "Causes are rooted in natural data properties, mathematical convenience, and assumptions made to simplify modeling.\n\nEffects are practical benefits in computation, model stability, generative performance, and probabilistic reasoning.\n\nKey Insight: Understanding this distinction helps AI practitioners choose appropriate models, justify assumptions, and anticipate model behavior."
        }
      ]
    },
    {
      "id": "sse-read-timeout-error",
      "title": "Fixing SSE ReadTimeout Error in MCP Client",
      "slug": "sse-read-timeout-error",
      "category": "tutorial",
      "categoryLabel": "Tutorial",
      "date": "2025-11-10",
      "readTime": "8 min read",
      "author": {
        "name": "Duc Le",
        "avatar": "data/images/image_avatar.jpg",
        "title": "Software Engineer & Researcher"
      },
      "excerpt": "A comprehensive guide to diagnosing and resolving Server-Sent Events (SSE) ReadTimeout errors in MCP client applications, with practical solutions and best practices.",
      "image": "https://via.placeholder.com/1200x600",
      "tags": ["SSE", "Python", "httpx", "Error Handling", "Real-time", "Debugging"],
      "featured": true,
      "sections": [
        {
          "id": "issue-description",
          "title": "I. Issue Description",
          "content": "This error occurs when the client attempts to read data from a Server-Sent Events (SSE) connection, but the server takes too long to respond. The underlying cause is a ReadTimeout raised by httpx, which wraps a lower-level httpcore.ReadTimeout."
        },
        {
          "id": "error-log",
          "title": "Error Log",
          "content": "```\n2025-11-10 02:19:08,976 - mcp.client.sse - ERROR - Error in sse_reader\nTraceback (most recent call last):\n  ...\nhttpx.ReadTimeout\n```"
        },
        {
          "id": "impact",
          "title": "Impact",
          "content": "The client stops receiving SSE messages from the server.\n\nReal-time event streaming is interrupted.\n\nDepending on retry configuration, the process may hang or attempt reconnection repeatedly."
        },
        {
          "id": "root-cause",
          "title": "Root Cause",
          "content": "The server response time exceeds the configured timeout threshold in the HTTP client (httpx). This can happen due to:\n\nHigh latency in the downstream service.\n\nNetwork congestion or unstable connection.\n\nLong-running tasks on the server delaying response streaming."
        },
        {
          "id": "solution",
          "title": "II. Solution",
          "content": "There are three main approaches to resolving this issue, depending on your specific use case and requirements."
        },
        {
          "id": "option1",
          "title": "Option 1 â€” Increase the HTTP Timeout",
          "content": "Adjust the timeout settings in the HTTP client to allow longer response times.\n\nExample:\n```python\nasync with httpx.AsyncClient(timeout=httpx.Timeout(60.0)) as client:\n    ...\n```\n\nUse this if the server is known to produce delayed but valid responses."
        },
        {
          "id": "option2",
          "title": "Option 2 â€” Reduce Latency in the Service",
          "content": "Optimize the server-side SSE response logic to send heartbeat events more frequently.\n\nEnsure that long-running operations are processed asynchronously or offloaded to background tasks.\n\nValidate that network bandwidth and load balancer configurations are not throttling streaming responses."
        },
        {
          "id": "option3",
          "title": "Option 3 â€” Implement Retry and Backoff Logic",
          "content": "Add automatic reconnection logic when ReadTimeout occurs.\n\nUse exponential backoff to prevent flooding the server with reconnection attempts.\n\nExample:\n```python\nimport asyncio\nfrom httpx import ReadTimeout\n\nmax_retries = 3\nbackoff_factor = 2\n\nfor attempt in range(max_retries):\n    try:\n        async with client.stream('GET', sse_url) as response:\n            async for line in response.aiter_lines():\n                process_sse_event(line)\n        break\n    except ReadTimeout:\n        if attempt < max_retries - 1:\n            wait_time = backoff_factor ** attempt\n            await asyncio.sleep(wait_time)\n        else:\n            raise\n```"
        },
        {
          "id": "best-practices",
          "title": "Best Practices",
          "content": "Always configure appropriate timeout values based on your application's requirements.\n\nImplement health check endpoints to monitor SSE connection status.\n\nUse logging to track timeout occurrences and identify patterns.\n\nConsider implementing circuit breaker patterns for production systems.\n\nMonitor server performance metrics to identify bottlenecks early."
        },
        {
          "id": "conclusion",
          "title": "Conclusion",
          "content": "SSE ReadTimeout errors are common in real-time streaming applications. By understanding the root cause and implementing appropriate solutionsâ€”whether through timeout adjustments, server optimization, or retry logicâ€”you can build more resilient systems that handle network variability gracefully."
        }
      ]
    }
  ]
}
